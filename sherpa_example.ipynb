{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherpa Example For Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import sherpa\n",
    "import sherpa.schedulers\n",
    "import sherpa.algorithms\n",
    "\n",
    "\n",
    "# Directory where files will be saved.\n",
    "OVERWRITE  = True\n",
    "output_dir = '' # All files (logs, results, etc.) written to here.\n",
    "if os.path.isdir(output_dir) and OVERWRITE:\n",
    "    print('Warning: Overwriting directory {}'.format(output_dir))\n",
    "    import shutil\n",
    "    shutil.rmtree(output_dir)\n",
    "elif os.path.isdir(output_dir) and not OVERWRITE:\n",
    "    print('Warning: Directory exists. Skipping {}'.format(output_dir))\n",
    "    raise Exception\n",
    "else:\n",
    "    print('Writing to directory {}'.format(output_dir))\n",
    "\n",
    "# # Hyperparameter dict\n",
    "# # Simple version for quickly checking a few hp configurations\n",
    "# hp_space = {\n",
    "#     'batch_size':      [128, 512],\n",
    "#     'act':             ['relu', 'tanh'],\n",
    "#     'opt':             ['sgd', 'adam'],\n",
    "#     'h_units':         [64, 256],\n",
    "#     'epochs':          [50],\n",
    "#     'early_stopping':  [3], # patience\n",
    "#     'checkpoint_path': [output_dir],\n",
    "# }\n",
    "# parameters = sherpa.Parameter.grid(hp_space)\n",
    "\n",
    "# More flexible, generally better alternative:\n",
    "# For details: https://parameter-sherpa.readthedocs.io/en/latest/gettingstarted/guide.html#parameters\n",
    "parameters = [sherpa.Ordinal(name='size', range=[1]),\n",
    "              sherpa.Ordinal(name='cwave', range=[True])]\n",
    "\n",
    "algorithm = sherpa.algorithms.GridSearch(repeat=6)\n",
    "# For other available algorithms: https://parameter-sherpa.readthedocs.io/en/latest/algorithms/algorithms.html\n",
    "# env is the .profile file that executes all set up required. \n",
    "env = ''  # insert your name\n",
    "# SLURM options\n",
    "opt = ''\n",
    "# For details on slurm& the hpc cluster: https://www.hawaii.edu/its/ci/hpc-tutor/\n",
    "scheduler = sherpa.schedulers.SLURMScheduler(environment=env, submit_options=opt, output_dir=output_dir)\n",
    "\n",
    "# Runner file\n",
    "filename = 'combinedNoVal.py' # Main method takes takes in parameters and sends results to mongodb.\n",
    "\n",
    "results = sherpa.optimize(parameters=parameters,\n",
    "                          algorithm=algorithm,\n",
    "                          lower_is_better=True,\n",
    "                          filename=filename,\n",
    "                          output_dir=output_dir,\n",
    "                          scheduler=scheduler,\n",
    "                          max_concurrent=22,\n",
    "                          verbose=1,\n",
    "                          db_port=8887,\n",
    "                          mongodb_args={'bind_ip_all':''}\n",
    "                         )\n",
    "print(results)\n",
    "pkl.dump(results, open(output_dir+'/results.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of loading and predicting using ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from generator import gen_data\n",
    "\n",
    "# HDF5 file storing data\n",
    "data_path = ''\n",
    "\n",
    "dataset = h5py.File(data_path, 'r')\n",
    "X = dataset['X_test']\n",
    "y_true = np.array(dataset['y_test'])\n",
    "y_pred = np.zeros((y_true.shape[0], 1))\n",
    "model_dir = ''\n",
    "for i in range(6):\n",
    "    model = load_model(model_dir + 'ensemble_{}.h5'.format(i + 1))\n",
    "    temp = model.predict_generator(gen_data(data_path, 'test', 1024), steps = X.shape[0] // 1024 + 1, verbose=1)\n",
    "    y_pred += temp[:y_true.shape[0]]\n",
    "y_pred /= 6\n",
    "y_pred = y_pred.reshape((19980,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = dataset[\"X2_test\"]\n",
    "data = pd.DataFrame({\"Labels\": y_true, \"Predictions\": y_pred, \"Time of Day\": X[:, 0], \"Incidence Angle\": X[:, 7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"predictions_buoy.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"predictions_features_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data[\"timeSAR\"] = np.load(\"times.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"predictions_with_times.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Of Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_true.reshape(-1) - y_pred.reshape(-1)\n",
    "print(np.sqrt(np.mean((residuals)**2)))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_true, residuals)\n",
    "plt.title('Residuals of Test Set vs. True Label')\n",
    "plt.ylabel('Residuals (True - Prediction)')\n",
    "plt.xlabel('True Label')\n",
    "plt.show()\n",
    "plt.scatter(y_true, y_pred)\n",
    "plt.title('Prediction vs. True Label')\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('True Label')\n",
    "plt.show()\n",
    "hs_large = (y_true > 8).nonzero()\n",
    "large_true = y_true[hs_large]\n",
    "large_pred = y_pred[hs_large]\n",
    "res = large_true.reshape(-1) - large_pred.reshape(-1)\n",
    "print(np.sqrt(np.mean((res)**2)), len(large_true))\n",
    "hs_small = (y_true < 1).nonzero()\n",
    "small_true = y_true[hs_small]\n",
    "small_pred = y_pred[hs_small]\n",
    "small_res = small_true.reshape(-1) - small_pred.reshape(-1)\n",
    "print(np.sqrt(np.mean((small_res) ** 2)), len(small_true))\n",
    "hs_meds = np.where(np.logical_and(y_true>1, y_true<3))\n",
    "meds_true = y_true[hs_meds]\n",
    "meds_pred = y_pred[hs_meds]\n",
    "res = meds_true.reshape(-1) - meds_pred.reshape(-1)\n",
    "print(np.sqrt(np.mean((res)**2)), len(meds_true))\n",
    "hs_medl = np.where(np.logical_and(y_true>3, y_true<8))\n",
    "medl_true = y_true[hs_medl]\n",
    "medl_pred = y_pred[hs_medl]\n",
    "res = medl_true.reshape(-1) - medl_pred.reshape(-1)\n",
    "print(np.sqrt(np.mean((res)**2)), len(medl_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_true, residuals)\n",
    "plt.title('Residuals of Test Set vs. True Label')\n",
    "plt.ylabel('Residuals (True - Prediction)')\n",
    "plt.xlabel('True Label')\n",
    "plt.show()\n",
    "plt.scatter(y_true, y_pred)\n",
    "plt.title('Prediction vs. True Label')\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
